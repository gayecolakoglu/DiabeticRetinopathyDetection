{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gayecolakoglu/DiabeticRetinopathyDetection/blob/main/HyperparameterTuning_VGG16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_q-Yce8y-O4",
        "outputId": "429788da-099b-4bdc-97f3-c00989340e38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "import pathlib\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive',force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uNLGSZfuhH9s"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "from numpy import argmax\n",
        "import pandas as pd\n",
        "import json\n",
        "from collections import OrderedDict, namedtuple\n",
        "from itertools import product\n",
        "from PIL import Image\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore', category=FutureWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0q0ofgQOhjAY",
        "outputId": "f0bdc564-1968-4938-b7f3-87a73ae9ccaf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device type: cpu\n"
          ]
        }
      ],
      "source": [
        "# Enable GPU processing\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'Device type: {device}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNkPsB33mfJy",
        "outputId": "e5e381e9-4ecf-4fe0-c01f-0480c2ca2307"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f4bca5958d0>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Set random seed\n",
        "seed = 777\n",
        "torch.manual_seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QN1FRbLf3sG9",
        "outputId": "5c0c807b-a6d1-4c05-9955-a004c27ec9a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting split-folders\n",
            "  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.5.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Copying files: 193 files [01:15,  2.54 files/s]\n"
          ]
        }
      ],
      "source": [
        "!pip install split-folders\n",
        "import splitfolders\n",
        "splitfolders.ratio('/content/gdrive/MyDrive/KaggleImageData/UfukHocaVeri', output=\"output\", seed=1337, ratio=(.7,.1,.2)) #train val test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FwyYVt13mfQj"
      },
      "outputs": [],
      "source": [
        "# Define data directory parameters\n",
        "datadir = '/content/output/'\n",
        "traindir = datadir + 'train/'\n",
        "validdir = datadir + 'val/'\n",
        "testdir = datadir + 'test/'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jCfYNVomfTU",
        "outputId": "d66c7797-dc14-42aa-d58c-240aae09ced6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classes: ['evre4padaphist', 'evre1padaphist', 'evre2padaphist', 'evre3padaphist', 'normalpadaphist']\n",
            "Training images per class: [11, 33, 18, 17, 53]\n",
            "Validation images per class: [1, 4, 2, 2, 7]\n",
            "Test images per class: [5, 11, 7, 6, 16]\n"
          ]
        }
      ],
      "source": [
        "# Confirm image class distribution\n",
        "\n",
        "# Empty lists\n",
        "classes = []\n",
        "n_train = []\n",
        "n_valid = []\n",
        "n_test = []\n",
        "\n",
        "# Iterate through each category\n",
        "for d in os.listdir(traindir):\n",
        "    classes.append(d)\n",
        "\n",
        "    # Number of each image\n",
        "    train_imgs = os.listdir(traindir + d)\n",
        "    valid_imgs = os.listdir(validdir + d)\n",
        "    test_imgs = os.listdir(testdir + d)\n",
        "    n_train.append(len(train_imgs))\n",
        "    n_valid.append(len(valid_imgs))\n",
        "    n_test.append(len(test_imgs))\n",
        "\n",
        "print(f'Classes: {classes}')\n",
        "print(f'Training images per class: {n_train}')\n",
        "print(f'Validation images per class: {n_valid}')\n",
        "print(f'Test images per class: {n_test}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfO8JNG-LGHv"
      },
      "source": [
        "Image Augmentation / Transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D3Re9xelmmd7"
      },
      "outputs": [],
      "source": [
        "# Define an image transformations dictionary\n",
        "image_transforms = {\n",
        "    # Training set uses data augmentation\n",
        "    'train':\n",
        "    transforms.Compose([                        \n",
        "        transforms.Resize(size=256),\n",
        "        transforms.RandomAffine(degrees=(0,30)),\n",
        "        transforms.RandomHorizontalFlip(), \n",
        "        transforms.CenterCrop(size=224),       \n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # Imagenet standards\n",
        "    ]),\n",
        "    # No image augmentation for the validation and test sets\n",
        "    'val':\n",
        "    transforms.Compose([\n",
        "        transforms.Resize(size=256),\n",
        "        transforms.CenterCrop(size=224),  \n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'test':\n",
        "    transforms.Compose([\n",
        "        transforms.Resize(size=256),\n",
        "        transforms.CenterCrop(size=224),  \n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJ1KOOGxh3ed"
      },
      "outputs": [],
      "source": [
        "# Load the data from each folder\n",
        "data = {\n",
        "    'train':\n",
        "    datasets.ImageFolder(root=traindir, transform=image_transforms['train']),\n",
        "    'val':\n",
        "    datasets.ImageFolder(root=validdir, transform=image_transforms['val']),\n",
        "    'test':\n",
        "    datasets.ImageFolder(root=testdir, transform=image_transforms['test'])\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffZL5ohMLW3A"
      },
      "source": [
        "Create CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867,
          "referenced_widgets": [
            "fbddc1b15956447ba3190c38cd824757",
            "e3d7975b486045c08ebd1dfa8b6419c1",
            "1665b4cc8dd645e5976473595a662528",
            "9a6c6637a10d4de19546973aff5f6d9b",
            "8bfb657c2fa641dcb80c42e9ee1dbe69",
            "cb3fab01cc1c4b429d6ec899e7fae09c",
            "55d6f1f09353449aabc418330364241b",
            "44308db6ee3d47529a26f3ae630446b7",
            "13b42920b4e94dd3bc2a0e35b5808ba2",
            "cb76134d2c494a2e8c5380cb3c3e3b4f",
            "d1c47ad78ee542aa81f4f9122c9d0cbc"
          ]
        },
        "id": "Z0_OsJEYh3jo",
        "outputId": "38929ac6-6704-4e80-c35f-6e5e84548faf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fbddc1b15956447ba3190c38cd824757",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0.00/528M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): ReLU(inplace=True)\n",
            "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (20): ReLU(inplace=True)\n",
            "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): ReLU(inplace=True)\n",
            "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Review the transfer learning model: using VGG-16\n",
        "review_model = models.vgg16(pretrained=True)\n",
        "print(review_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fgL0fqWJh3lv"
      },
      "outputs": [],
      "source": [
        "# Create our CNN model by modifying the output layer of the transfer learning model\n",
        "def CNN_model(hidden_units, dropout, num_classes):\n",
        "  transfer_model = models.vgg16(pretrained=True)\n",
        "  \n",
        "  # freeze the weights from training in the transfer learning model\n",
        "  for param in transfer_model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "  # define the overall CNN model\n",
        "  model = transfer_model\n",
        "  model.classifier = nn.Sequential(\n",
        "    nn.Linear(in_features=25088, out_features=4096),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.Dropout(dropout, inplace=False),\n",
        "    nn.Linear(in_features=4096, out_features=hidden_units),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.Dropout(dropout, inplace=False),\n",
        "    nn.Linear(hidden_units, num_classes),\n",
        "    nn.LogSoftmax(dim=1)    \n",
        "  )\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ws0YnA0K3v8f",
        "outputId": "c6ba823f-a145-4b32-9d9e-b15588a4345c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): ReLU(inplace=True)\n",
            "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (20): ReLU(inplace=True)\n",
            "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): ReLU(inplace=True)\n",
            "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.4, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=256, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.4, inplace=False)\n",
            "    (6): Linear(in_features=256, out_features=4, bias=True)\n",
            "    (7): LogSoftmax(dim=1)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Test model creation\n",
        "test_model = CNN_model(256, 0.4, 4)\n",
        "print(test_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQbyR9L7LbeP"
      },
      "source": [
        "Create Training Execution Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBE2MUv3V4NU"
      },
      "source": [
        "A Python class is defined to generate a list of run definitions across the various parameter permutations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDGsWj1_DATs"
      },
      "outputs": [],
      "source": [
        "# Define a class to build run execution sets based on a dictionary of hyperparameters\n",
        "class RunBuilder():\n",
        "  @staticmethod\n",
        "  def get_runs(params):\n",
        "    Run = namedtuple('Run', params.keys())\n",
        "    runs = []\n",
        "    for v in product(*params.values()):\n",
        "      runs.append(Run(*v))\n",
        "    return runs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJ7zR6o3V_Yf"
      },
      "source": [
        "A RunManager class is created to define a set of methods for managing the run and epoch parameter initializations, to track the training outputs and feed the output data to TensorBoard."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7F6EIJmDDAWK"
      },
      "outputs": [],
      "source": [
        "# Create a class to manage the training / hyperparameter runs\n",
        "class RunManager():\n",
        "  def __init__(self):\n",
        "    self.epoch_count = 0\n",
        "    self.train_loss = 0\n",
        "    self.train_num_correct = 0\n",
        "    self.val_loss = 0\n",
        "    self.val_num_correct = 0\n",
        "\n",
        "    self.run_params = None\n",
        "    self.run_count = 0\n",
        "    self.run_data = []\n",
        "\n",
        "    self.model = None\n",
        "    self.train_loader = None\n",
        "    self.val_loader = None\n",
        "    self.tb = None\n",
        "\n",
        "  def begin_run(self, run, model, train_loader, val_loader):\n",
        "    self.run_params = run\n",
        "    self.run_count += 1\n",
        "    self.model = model.to(device)\n",
        "    self.train_loader = train_loader\n",
        "    self.val_loader = val_loader\n",
        "    self.tb = SummaryWriter(log_dir=traindir + '/runs', max_queue=20, comment=f'-{run}')\n",
        "    images, labels = next(iter(self.train_loader))\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "    self.tb.add_graph(self.model, images)\n",
        "\n",
        "  def end_run(self):\n",
        "    self.tb.close()\n",
        "    self.epoch_count = 0\n",
        "\n",
        "  def begin_epoch(self):\n",
        "    self.epoch_count += 1\n",
        "    self.train_loss = 0\n",
        "    self.train_num_correct = 0\n",
        "    self.val_loss = 0\n",
        "    self.val_num_correct = 0\n",
        "\n",
        "  def end_epoch(self):\n",
        "    train_loss = self.train_loss / len(self.train_loader.dataset)\n",
        "    train_accuracy = self.train_num_correct / len(self.train_loader.dataset)\n",
        "    val_loss = self.val_loss / len(self.val_loader.dataset)\n",
        "    val_accuracy = self.val_num_correct / len(self.val_loader.dataset)\n",
        "\n",
        "    self.tb.add_scalar('Train Loss', train_loss, self.epoch_count)\n",
        "    self.tb.add_scalar('Train Accuracy', train_accuracy, self.epoch_count)\n",
        "    self.tb.add_scalar('Val Loss', val_loss, self.epoch_count)\n",
        "    self.tb.add_scalar('Val Accuracy', val_accuracy, self.epoch_count)\n",
        "\n",
        "    for name, param in self.model.named_parameters():\n",
        "      self.tb.add_histogram(name, param, self.epoch_count)\n",
        "      #self.tb.add_histogram(f'{name}.grad', param.grad, self.epoch_count)\n",
        "\n",
        "    print(f'Epoch: {self.epoch_count}, Train Loss: {train_loss:.3f}, Train Acc: {train_accuracy:.3f}')\n",
        "    print(f'Epoch: {self.epoch_count}, Valid Loss: {val_loss:.3f}, Valid Acc: {val_accuracy:.3f}')\n",
        "    \n",
        "    results = OrderedDict()\n",
        "    results['run'] = self.run_count\n",
        "    results['epoch'] = self.epoch_count\n",
        "    results['train loss'] = train_loss\n",
        "    results['train acc'] = train_accuracy\n",
        "    results['valid loss'] = val_loss\n",
        "    results['valid acc'] = val_accuracy\n",
        "\n",
        "    for k, v in self.run_params._asdict().items():\n",
        "      results[k] = v\n",
        "\n",
        "    self.run_data.append(results)\n",
        "\n",
        "  def track_loss(self, loss, mode):\n",
        "    if mode == 'train':\n",
        "      self.train_loss += loss.item() * self.train_loader.batch_size\n",
        "    elif mode == 'val':\n",
        "      self.val_loss += loss.item() * self.val_loader.batch_size\n",
        "\n",
        "  def track_num_correct(self, preds, labels, mode):\n",
        "    if mode == 'train':\n",
        "      self.train_num_correct += preds.argmax(dim=1).eq(labels).sum().item()\n",
        "    elif mode == 'val':\n",
        "      self.val_num_correct += preds.argmax(dim=1).eq(labels).sum().item()\n",
        "\n",
        "  def save_output(self, filename):\n",
        "    if filename:\n",
        "      filename = traindir + filename\n",
        "      pd.DataFrame.from_dict(self.run_data, orient='columns').to_csv(f'{filename}.csv')\n",
        "      \n",
        "      # with open(f'{filename}.json', 'w', encoding='utf-8') as f:\n",
        "      #   json.dump(self.run_data, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "      print('Results saved to disk')\n",
        "\n",
        "    return pd.DataFrame.from_dict(self.run_data, orient='columns')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nSXbGKGQDAYn"
      },
      "outputs": [],
      "source": [
        "# Define training loop execution\n",
        "def execution_loop(filename):\n",
        "  m = RunManager()\n",
        "  for run in RunBuilder.get_runs(params):\n",
        "\n",
        "    # instantiate the neural network model\n",
        "    model = CNN_model(run.hidden_units, run.dropout, run.num_classes)\n",
        "    optimizer = Adam(model.parameters(), lr=run.lr)\n",
        "    \n",
        "    # Define the data loaders\n",
        "    dataloaders = {\n",
        "        'train': DataLoader(data['train'], batch_size=run.batch_size, shuffle=True, num_workers=1),\n",
        "        'val': DataLoader(data['val'], batch_size=run.batch_size, shuffle=False, num_workers=1)\n",
        "    }\n",
        "\n",
        "    train_loader = dataloaders['train']\n",
        "    val_loader = dataloaders['val']  \n",
        "        \n",
        "    # Execute the PyTorch training loop per epoch. PyTorch gradient calculation is turned on for training, but turned off during the processing of the validation data.\n",
        "    m.begin_run(run, model, train_loader, val_loader)\n",
        "    for epoch in range(run.n_epochs):\n",
        "      m.begin_epoch()\n",
        "      for batch in train_loader:\n",
        "        with torch.set_grad_enabled(True):\n",
        "          # get inputs/targets and move tensors to GPU\n",
        "          images, labels = batch[0].to(device), batch[1].to(device)\n",
        "          # clear previous gradients\n",
        "          optimizer.zero_grad()\n",
        "          # make prediction\n",
        "          yhat = model(images)\n",
        "          # calculate the loss\n",
        "          loss = F.nll_loss(yhat, labels)\n",
        "          # perform back prop\n",
        "          loss.backward()\n",
        "          # update model weights\n",
        "          optimizer.step()\n",
        "\n",
        "          m.track_loss(loss, 'train')\n",
        "          m.track_num_correct(yhat, labels, 'train')\n",
        "\n",
        "      else:\n",
        "        with torch.no_grad():\n",
        "          for batch in val_loader:\n",
        "            images, labels = batch[0].to(device), batch[1].to(device)\n",
        "            output = model(images)\n",
        "            loss = F.nll_loss(output, labels)\n",
        "\n",
        "            m.track_loss(loss, 'val')\n",
        "            m.track_num_correct(output, labels, 'val')\n",
        "\n",
        "      m.end_epoch()\n",
        "    m.end_run()\n",
        "  return model, m.save_output(filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRo2i5N_VozY"
      },
      "source": [
        "To explore various model and hyperparameter settings during the model training process, the model parameters are defined in a Python ordered dictionary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XnwVTWlODAbM"
      },
      "outputs": [],
      "source": [
        "# Define training run hyperparameters\n",
        "params = OrderedDict(\n",
        "    hidden_units = [256, 512],\n",
        "    dropout = [0.4, 0.5],\n",
        "    num_classes = [5],\n",
        "    lr = [0.001],\n",
        "    batch_size = [25],\n",
        "    n_epochs = [15]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLBvemoiDAdq",
        "outputId": "0f648876-2ee5-4887-c948-3be145f900d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1, Train Loss: 4.849, Train Acc: 0.265\n",
            "Epoch: 1, Valid Loss: 2.806, Valid Acc: 0.562\n",
            "Epoch: 2, Train Loss: 2.377, Train Acc: 0.379\n",
            "Epoch: 2, Valid Loss: 2.099, Valid Acc: 0.500\n",
            "Epoch: 3, Train Loss: 1.628, Train Acc: 0.508\n",
            "Epoch: 3, Valid Loss: 1.966, Valid Acc: 0.438\n",
            "Epoch: 4, Train Loss: 1.308, Train Acc: 0.500\n",
            "Epoch: 4, Valid Loss: 1.562, Valid Acc: 0.625\n",
            "Epoch: 5, Train Loss: 1.110, Train Acc: 0.561\n",
            "Epoch: 5, Valid Loss: 1.755, Valid Acc: 0.500\n",
            "Epoch: 6, Train Loss: 1.116, Train Acc: 0.553\n",
            "Epoch: 6, Valid Loss: 1.708, Valid Acc: 0.500\n",
            "Epoch: 7, Train Loss: 1.148, Train Acc: 0.606\n",
            "Epoch: 7, Valid Loss: 1.463, Valid Acc: 0.688\n",
            "Epoch: 8, Train Loss: 1.169, Train Acc: 0.591\n",
            "Epoch: 8, Valid Loss: 1.731, Valid Acc: 0.562\n",
            "Epoch: 9, Train Loss: 0.853, Train Acc: 0.674\n",
            "Epoch: 9, Valid Loss: 1.554, Valid Acc: 0.625\n",
            "Epoch: 10, Train Loss: 0.926, Train Acc: 0.652\n",
            "Epoch: 10, Valid Loss: 1.584, Valid Acc: 0.500\n",
            "Epoch: 11, Train Loss: 1.060, Train Acc: 0.652\n",
            "Epoch: 11, Valid Loss: 1.193, Valid Acc: 0.562\n",
            "Epoch: 12, Train Loss: 0.654, Train Acc: 0.765\n",
            "Epoch: 12, Valid Loss: 1.422, Valid Acc: 0.500\n",
            "Epoch: 13, Train Loss: 0.618, Train Acc: 0.765\n",
            "Epoch: 13, Valid Loss: 2.516, Valid Acc: 0.438\n",
            "Epoch: 14, Train Loss: 0.534, Train Acc: 0.833\n",
            "Epoch: 14, Valid Loss: 2.152, Valid Acc: 0.562\n",
            "Epoch: 15, Train Loss: 0.494, Train Acc: 0.841\n",
            "Epoch: 15, Valid Loss: 2.627, Valid Acc: 0.438\n",
            "Epoch: 16, Train Loss: 0.771, Train Acc: 0.765\n",
            "Epoch: 16, Valid Loss: 2.404, Valid Acc: 0.500\n",
            "Epoch: 17, Train Loss: 0.420, Train Acc: 0.856\n",
            "Epoch: 17, Valid Loss: 2.406, Valid Acc: 0.562\n",
            "Epoch: 18, Train Loss: 0.412, Train Acc: 0.841\n",
            "Epoch: 18, Valid Loss: 1.995, Valid Acc: 0.562\n",
            "Epoch: 19, Train Loss: 0.532, Train Acc: 0.841\n",
            "Epoch: 19, Valid Loss: 2.601, Valid Acc: 0.500\n",
            "Epoch: 20, Train Loss: 0.483, Train Acc: 0.871\n",
            "Epoch: 20, Valid Loss: 2.120, Valid Acc: 0.562\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-84a28a850d6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Run_Results'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-df4e1d56e8dd>\u001b[0m in \u001b[0;36mexecution_loop\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     28\u001b[0m           \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m           \u001b[0;31m# make prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m           \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m           \u001b[0;31m# calculate the loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m           \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/models/vgg.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavgpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    442\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    443\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 444\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model, history = execution_loop('Run_Results')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Jxu4pJRyDAgH"
      },
      "outputs": [],
      "source": [
        "# Function to evaluate the model on the test set\n",
        "def evaluate_model(test_dl, model):\n",
        "    predictions, actuals = list(), list()\n",
        "    for i, (inputs, targets) in enumerate(test_dl):\n",
        "        # evaluate the model on the test set\n",
        "        yhat = model(inputs)\n",
        "        # retrieve numpy array\n",
        "        yhat = yhat.detach().numpy()\n",
        "        actual = targets.numpy()\n",
        "        actual = actual.reshape((len(actual), 1))\n",
        "        # round to class values\n",
        "        yhat = yhat.round()\n",
        "        # store\n",
        "        predictions.append(yhat)\n",
        "        actuals.append(actual)\n",
        "    predictions, actuals = vstack(predictions), vstack(actuals)\n",
        "    # calculate accuracy\n",
        "    acc = accuracy_score(actuals, predictions)\n",
        "    return acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JhHlMHUkDAis"
      },
      "outputs": [],
      "source": [
        "# Determine model accuracy on the test set\n",
        "test_dl = DataLoader(data['test'], batch_size=params['batch_size'], shuffle=False, num_workers=1)\n",
        "test_acc = evaluate_model(test_dl, model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bpwWbFew8LV8"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "HyperparameterTuning-VGG16.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM3V98H5hRY7TMgU1Mo0leE",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "13b42920b4e94dd3bc2a0e35b5808ba2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1665b4cc8dd645e5976473595a662528": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44308db6ee3d47529a26f3ae630446b7",
            "max": 553433881,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_13b42920b4e94dd3bc2a0e35b5808ba2",
            "value": 553433881
          }
        },
        "44308db6ee3d47529a26f3ae630446b7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55d6f1f09353449aabc418330364241b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8bfb657c2fa641dcb80c42e9ee1dbe69": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a6c6637a10d4de19546973aff5f6d9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb76134d2c494a2e8c5380cb3c3e3b4f",
            "placeholder": "​",
            "style": "IPY_MODEL_d1c47ad78ee542aa81f4f9122c9d0cbc",
            "value": " 528M/528M [00:05&lt;00:00, 105MB/s]"
          }
        },
        "cb3fab01cc1c4b429d6ec899e7fae09c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb76134d2c494a2e8c5380cb3c3e3b4f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1c47ad78ee542aa81f4f9122c9d0cbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e3d7975b486045c08ebd1dfa8b6419c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb3fab01cc1c4b429d6ec899e7fae09c",
            "placeholder": "​",
            "style": "IPY_MODEL_55d6f1f09353449aabc418330364241b",
            "value": "100%"
          }
        },
        "fbddc1b15956447ba3190c38cd824757": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e3d7975b486045c08ebd1dfa8b6419c1",
              "IPY_MODEL_1665b4cc8dd645e5976473595a662528",
              "IPY_MODEL_9a6c6637a10d4de19546973aff5f6d9b"
            ],
            "layout": "IPY_MODEL_8bfb657c2fa641dcb80c42e9ee1dbe69"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}